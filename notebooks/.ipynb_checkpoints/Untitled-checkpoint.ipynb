{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e93896ce-42a3-477f-ab35-2b1bd9f42bc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../artifacts/embeddings.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 122\u001b[0m\n\u001b[0;32m    119\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m    121\u001b[0m obj\u001b[38;5;241m=\u001b[39mAnnoyIndexer()\n\u001b[1;32m--> 122\u001b[0m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m obj\u001b[38;5;241m.\u001b[39msave_index()\n",
      "Cell \u001b[1;32mIn[1], line 30\u001b[0m, in \u001b[0;36mAnnoyIndexer.build_index\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     26\u001b[0m n_trees \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# Number of trees\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Create a dummy embeddings dictionary\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# importing the embedding json file\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../artifacts/embeddings.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     31\u001b[0m     embeddings_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Initialize Annoy index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../artifacts/embeddings.json'"
     ]
    }
   ],
   "source": [
    "\"\"\" THIS PYTHON FILE CONTAINS THE CLASS FOR INDEXING EMBEDDINGS USING ANNOY\"\"\"\n",
    "\n",
    "# importing the required libraries\n",
    "import numpy as np\n",
    "from annoy import AnnoyIndex\n",
    "import os\n",
    "from functools import reduce\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# building a class for storing and searching in the index\n",
    "class AnnoyIndexer:\n",
    "\n",
    "    \"\"\" A class to built and search an annoy index \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.index=None\n",
    "\n",
    "\n",
    "    \n",
    "    def build_index(self):\n",
    "       \n",
    "        # Example configuration\n",
    "        embedding_size = 384  # Example embedding size\n",
    "        n_trees = 10  # Number of trees\n",
    "\n",
    "        # Create a dummy embeddings dictionary\n",
    "        # importing the embedding json file\n",
    "        with open('../../artifacts/embeddings.json', 'r') as file:\n",
    "            embeddings_dict = json.load(file)\n",
    "                \n",
    "\n",
    "        # Initialize Annoy index\n",
    "        index = AnnoyIndex(embedding_size, 'euclidean')\n",
    "\n",
    "        # Add items to the index\n",
    "        for i, embedding in embeddings_dict.items():\n",
    "            index.add_item(int(i), embedding)\n",
    "\n",
    "        # Build the index\n",
    "        try:\n",
    "            index.build(n_trees)\n",
    "            print(\"Successfully built the index\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error building the index: {e}\")\n",
    "\n",
    "        # Save the index\n",
    "        index.save('artifacts/TEST_annoy_index.ann')\n",
    "        print(\"Index saved\")\n",
    "\n",
    "            \n",
    "       \n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "    def search(self, query_embedding:list, k:int, ids_lookup:dict=None)->list:\n",
    "        \"\"\"\n",
    "        searches for the K nearest neighbors for the given query embedding\n",
    "\n",
    "        query_embedding    : list of embedding of the queries we want to search\n",
    "        k                  : no of nearest neightbor that we want to return\n",
    "        ids_lookup         : a dictionary mapping where keys are article_ids and values are the embeddings\n",
    "         \n",
    "        returns a list of tuples of the form  [ (id,distance) , (id,distance) ]\n",
    "        \"\"\"\n",
    "\n",
    "        # defining an empty list to store the results\n",
    "        results = []\n",
    "\n",
    "        for query in query_embedding:\n",
    "            # getting the k nearest neightbor for the embedding\n",
    "            result = self.index.get_nns_by_vector(query, k, include_distances=True)\n",
    "            # result will be list of tuple of lists ( [a,b,c],[0.1,0.5,0.7] ) where a,b,c are indices(section_ids) and 0.1,0.5,0.7 are the similarity metrics\n",
    "            # now we want to map the section_ids to article_ids\n",
    "            ids =list( map( \n",
    "                           lambda x:ids_lookup[str(x)],\n",
    "                            result[0]\n",
    "                          ) )\n",
    "            # sorting the result based on the metrics in descending order\n",
    "            res = sorted( set(zip(ids,result[1])) ,lambda x:x[1], reverse=True)\n",
    "\n",
    "            # appeding the nearest neighbors in the result list\n",
    "            results.append(res)\n",
    "\n",
    "        return results\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def save_index(self,index_path:str):\n",
    "        \"\"\"\n",
    "        saves the index to the disk\n",
    "        index_path: path where we want to store our index\n",
    "        \"\"\"\n",
    "        self.index.save(index_path)\n",
    "        logging.info(f\"Index saved to {index_path}\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def load(self,index_path:str):\n",
    "        \"\"\"\n",
    "        loads the index from the disk\n",
    "        index_path  : path of the index \n",
    "        \"\"\"\n",
    "        self.index = AnnoyIndex(config.EMBEDDING_SIZE, config.ANNOY_METRIC)\n",
    "        self.index.load(index_path)\n",
    "        logging.info(f\"Index loaded from {index_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# importing the embedding json file\n",
    "with open('../artifacts/embeddings.json', 'r') as file:\n",
    "        embeddings = json.load(file)\n",
    "\n",
    "obj=AnnoyIndexer()\n",
    "obj.build_index()\n",
    "obj.save_index()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe9f1cf-222a-4724-9044-23e8dba0edf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
